-> There's going to be a 'sub-menu' for caching urls that will allow for either pulling down a specific url or loading up a list of urls in a text file: urls.txt with one url per line.
-> once the sites are scraped with scrapingbee, the content should be stored in the database
-> The submenu should have a "refresh" option that, when selected, re-scans the directory for a urls.txt file. 
-> Could you also implement an explanation of each of the selected options that shows when the menu option is selected.

-> Make sure that the menu is "beatiful", make extensive use of the ratatui_docs.md in order to accomplish this task. Make sure that the help-tips are actually helpful.

-> Implement a log file that the application adds all of its logs to